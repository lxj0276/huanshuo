{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n使用oneR算法来实现iris分类\\n参考:   http://www.cnblogs.com/htynkn/archive/2012/04/14/2446905.html\\n算法思路: 根据已有数据中，具有相同特征值的个体最可能属于哪个类别进行分类.\\noneR是one rule(一条规则)的简写, 表示只选取四个特征中分类效果最好的一个用作分类的依据. \\n步骤:\\n    #1. 离散化特征值: 因为oneR算法使用类别型特征值，而原数据集为连续值。因此需要把连续值转为类别型\\n        #简单的离散方法: 设定一个阈值，将低于该阈值的特征值置为0,高于阈值的置为1.  某特征的阈值设定为该特征所有特征值的均值.\\n    #2. 遍历每个特征的每一个取值，对于每一个特征值，统计它在各个类别中的出现次数。找到它出现次数最多的类别，并统计它在其它类别中的出现次数.\\n    #3. 统计完所有的特征值及其在每个类别的出现次数后，再计算每个特征的错误率。计算方法为把它的各个取值的错误率相加，选取错误率最低的特征作为唯一分类准则,用于接下来的分类\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "使用oneR算法来实现iris分类\n",
    "参考:   http://www.cnblogs.com/htynkn/archive/2012/04/14/2446905.html\n",
    "算法思路: 根据已有数据中，具有相同特征值的个体最可能属于哪个类别进行分类.\n",
    "oneR是one rule(一条规则)的简写, 表示只选取四个特征中分类效果最好的一个用作分类的依据. \n",
    "步骤:\n",
    "    #1. 离散化特征值: 因为oneR算法使用类别型特征值，而原数据集为连续值。因此需要把连续值转为类别型\n",
    "        #简单的离散方法: 设定一个阈值，将低于该阈值的特征值置为0,高于阈值的置为1.  某特征的阈值设定为该特征所有特征值的均值.\n",
    "    #2. 遍历每个特征的每一个取值，对于每一个特征值，统计它在各个类别中的出现次数。找到它出现次数最多的类别，并统计它在其它类别中的出现次数.\n",
    "    #3. 统计完所有的特征值及其在每个类别的出现次数后，再计算每个特征的错误率。计算方法为把它的各个取值的错误率相加，选取错误率最低的特征作为唯一分类准则,用于接下来的分类\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "n_samples,n_features=x.shape    #  结果为: (150,4) 取出数据行数及列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算每个特征列的均值\n",
    "attribute_means=x.mean(axis=0)   #axis=0表示列    1表示行   \n",
    "#以上结果为 ：  array([ 5.84333333,  3.054     ,  3.75866667,  1.19866667]) \n",
    "#将上面的结果转为一个数组，这个数组正好是四列，分别对应了四个特征值的均值，再用这个均值做阈值将数据集打散，将连续的特征值转为类别型，即完成步骤一\n",
    "x_d=np.array( x>=attribute_means, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4) training samples\n",
      "(38,) testing samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#接下来切分训练集和测试集， 切分数据集为训练集和测试集\n",
    "#方案一: 像上一个案例一样，切成140:10的比例\n",
    "#np.random.seed(0)\n",
    "# permutation函数: 随机排列   https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.permutation.html\n",
    "#i=np.random.permutation(len(x_d))\n",
    "#训练集： 取出打乱后的前140条数据\n",
    "#x_train=x_d[i[:-10]]   #前140条数据\n",
    "#y_train=y[i[:-10]]   #前140条数据对应的花的类型\n",
    "#输出x_train, y_train\n",
    "#x_train\n",
    "#y_train\n",
    "#测试集\n",
    "#x_test=x_d[i[-10:]]   #最后10条数据\n",
    "#y_test=y[i[-10:]]   #最后10条数据对应的花的类型\n",
    "#方案2: 利用 scikit-learn库提供的切分函数\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#train_test_split知识 :  http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html\n",
    "x_train,x_test,y_train,y_test=train_test_split( x_d,y,random_state=14)\n",
    "print(\"{} training samples\".format(x_train.shape))\n",
    "print(\"{} testing samples\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict   # http://www.pythontab.com/html/2013/pythonjichu_1023/594.html\n",
    "from operator import itemgetter       # http://www.cnblogs.com/100thMountain/p/4719503.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个函数: 遍历数据集中每一条数据，统计具有给定特征值的个体在各个类别中的出现次数\n",
    "            # 参数说明:   数据集 类别数组 选好的特征索引值 特征值\n",
    "def train_feature_value( X, y_true, feature_index, value):\n",
    "    class_counts=defaultdict(int)\n",
    "    #zip函数用法:  http://www.cnblogs.com/frydsh/archive/2012/07/10/2585370.html\n",
    "    for sample,y in zip(X, y_true):\n",
    "        if sample[feature_index]==value:\n",
    "                class_counts[y]+=1\n",
    "    #对class_counts字典排序，找到最大值，这就找到了具有给定特征值的个体在哪个类别中出现次数最多\n",
    "    sorted_class_counts=sorted(class_counts.items(), key=itemgetter(1),reverse=True)\n",
    "    most_frequent_class=sorted_class_counts[0][0]\n",
    "    #计算该条规则错误率\n",
    "    error=sum(  [ class_count for class_value,class_count in class_counts.items() if class_value!=most_frequent_class ])\n",
    "    return most_frequent_class,error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义另一个函数:\n",
    "    #对于某项特征，遍历其每一个特征值，调用上面的函数，就能得到预测结果和每个特征值所带来的错误率，然后把所有错误率累加起来，就能得到该特征的总错误率。\n",
    "def train(X,y_true,feature_index):\n",
    "    #以数组形式返回由feature_index所指的列的值.然后以set函数将数组转为集合. \n",
    "    values=set(X[:,feature_index])\n",
    "    #再创建字典\n",
    "    predictors=dict()\n",
    "    errors=[]\n",
    "    for current_value in values:\n",
    "        most_frequent_class,error=train_feature_value( X,y_true, feature_index, current_value)\n",
    "        predictors[current_value]=most_frequent_class\n",
    "        errors.append( error )\n",
    "    #最后计算该规则的总错误率\n",
    "    total_error=sum(errors)\n",
    "    return predictors,total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算预测器\n",
    "all_predictors={variable:train(x_train,y_train,variable) for variable in range(x_train.shape[1])}\n",
    "errors={variable:error for variable, (mapping,error) in all_predictors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出错误率最低的特征,作为分类的唯一规则\n",
    "best_feature,best_error=sorted(errors.items(),key=itemgetter(1))[0]\n",
    "#对预测器进行排序，找到最佳特征值,创建模型\n",
    "model={'feature':best_feature,'predictor':all_predictors[best_feature][0]}\n",
    "#model中的元素，一个用于分类的特征和预测器\n",
    "#下面可以开始对测试集进行预测了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先定义一个函数\n",
    "def predict( x_test,model):\n",
    "    feature=model['feature']\n",
    "    predictor=model['predictor']\n",
    "    y_predicted=np.array([predictor[int(sample[feature])] for sample in x_test])\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用上面的函数对测试集进行预测\n",
    "y_predicted=predict( x_test,model)\n",
    "#使用模型预测的结果:  array([0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0,\n",
    "  #     2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 0, 1, 0, 2, 2, 1, 0, 0,\n",
       "       0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n",
    "#标准结果: array([0, 0, 0, 1, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 0, 1, 0, 2, 2, 1, 0, 0, 0,\n",
    " #      1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型正确率为:65.8%\n"
     ]
    }
   ],
   "source": [
    "#计算正确率\n",
    "accuracy=np.mean( y_predicted==y_test)*100\n",
    "print(u\"模型正确率为:{:.1f}%\".format( accuracy))   # 65.8%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
